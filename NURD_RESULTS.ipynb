{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "from scipy import stats\n",
    "import tensorboard as t\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import glob\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from aggregate_results import parse_results\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "def get_seeds_from_result_strings(_result_strings):\n",
    "\tresult_seeds = []\n",
    "\tfor result_string in results_strings:\n",
    "\t\tsplitseed = result_string.split('seed')[1][:4]\n",
    "\t\tif splitseed[-1] == '_':\n",
    "\t\t\tsplitseed = splitseed[:-1]\n",
    "\t\tresult_seeds.append(int(splitseed))\n",
    "\treturn result_seeds\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def parse_results(glob_string, lambda_, avg_only=False, no_print=False):\n",
    "\n",
    "    result_strings = glob.glob(glob_string)\n",
    "    print(\"FOUND {} RESULTS\".format(len(result_strings)))\n",
    "    \n",
    "    if not no_print:\n",
    "        print(\"USED\" , glob_string)\n",
    "        # print(result_strings)\n",
    "    print(\"GOT THIS MANY\", len(result_strings))\n",
    "    \n",
    "    try:\n",
    "        result_strings = sorted(result_strings, key=lambda x: int(x[-4]))\n",
    "    except:\n",
    "        if not no_print:\n",
    "            print(\"No noise ordering.\")\n",
    "\n",
    "    empty_metric_dict = {\n",
    "        'pred_loss':[],\n",
    "        'acc' : [],\n",
    "        'info_loss' : [],\n",
    "        'total_loss' : []\n",
    "    }\n",
    "\n",
    "    agg_list = {'val' : copy.deepcopy(empty_metric_dict), 'test' : copy.deepcopy(empty_metric_dict)}\n",
    "    \n",
    "    print(glob_string)\n",
    "    if 'evaluations' in glob_string or \"GENNURD\" in glob_string:\n",
    "        agg_list['unbal_val'] = copy.deepcopy(empty_metric_dict)\n",
    "\n",
    "    for result_string in result_strings:\n",
    "        \n",
    "        result = torch.load(result_string)\n",
    "        \n",
    "        try:\n",
    "            if len(result[\"weight_model\"]) > 0:\n",
    "                weight_val_loss_dict_list = result['weight_model']\n",
    "                # print(weight_val_loss_dict_list)\n",
    "            else:\n",
    "                weight_val_loss_dict_list = None\n",
    "        except:\n",
    "            weight_val_loss_dict_list = None\n",
    "\n",
    "        pred_result_dict = result['final_results']\n",
    "        \n",
    "\n",
    "        for (key, metric_dict) in pred_result_dict.items():\n",
    "            if key not in ['val', 'test', 'unbal_val']:\n",
    "                continue\n",
    "            for metric_key, metric in metric_dict.items():\n",
    "                if metric_key in empty_metric_dict.keys():\n",
    "                    agg_list[key][metric_key].append(metric)\n",
    "            agg_list[key]['total_loss'].append(metric_dict['pred_loss'] + lambda_*metric_dict['info_loss'])\n",
    "        \n",
    "        # if not avg_only and not no_print:\n",
    "        # print(\" | \".join([\"{:20.4f}\".format(pred_result_dict[key]) for key in print_list]))\n",
    "    # print(agg_list)\n",
    "    metric_dict_of_dicts = {\n",
    "        'pred_loss':{},\n",
    "        'acc' : {},\n",
    "        'info_loss' : {},\n",
    "        'total_loss' : {}\n",
    "    }\n",
    "\n",
    "    consolidated_list = {'val' : copy.deepcopy(metric_dict_of_dicts), 'test' : copy.deepcopy(metric_dict_of_dicts)}\n",
    "    if 'evaluations' in glob_string  or \"GENNURD\" in glob_string:\n",
    "        consolidated_list['unbal_val'] = copy.deepcopy(metric_dict_of_dicts)\n",
    "        \n",
    "    for (key, metric_dict) in agg_list.items():\n",
    "        for metric_key, val_list in metric_dict.items():\n",
    "            # print(val_list)\n",
    "            if len(val_list) < 1:\n",
    "                continue\n",
    "            else:\n",
    "                consolidated_list[key][metric_key]['mean'] = np.mean(val_list)\n",
    "                consolidated_list[key][metric_key]['sem'] = np.std(val_list)/np.sqrt(len(val_list))\n",
    "                consolidated_list[key][metric_key]['median'] = np.median(val_list)\n",
    "                # print(val_list)\n",
    "                print(\" {:5s} {:10s} MIN/MAX         = {:.2f}/{:.2f}\".format(key, metric_key, np.min(val_list), np.max(val_list)))\n",
    "                print(\" {:5s} {:10s} MEAN/SEM/MEDIAN = {:.3f}/{:.3f}/{:.3f}\".format(\n",
    "                                                                                        \"\", \n",
    "                                                                                        \"\",\n",
    "                                                                                        consolidated_list[key][metric_key]['mean'],\n",
    "                                                                                        consolidated_list[key][metric_key]['sem'],\n",
    "                                                                                        consolidated_list[key][metric_key]['median']\n",
    "                )) \n",
    "                # print(\"\")\n",
    "\n",
    "    return agg_list, consolidated_list, result_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND 0 RESULTS\n",
      "USED ./LOGS/results_GENNURD_weight_joint_BALdownsample_BS1000_seed*_RHOTEST09_BORDER6_noBN_LONGGEN_DEFLR_distWD0_LAM1_FRAC2_RR1_LONG.pt\n",
      "GOT THIS MANY 0\n",
      "./LOGS/results_GENNURD_weight_joint_BALdownsample_BS1000_seed*_RHOTEST09_BORDER6_noBN_LONGGEN_DEFLR_distWD0_LAM1_FRAC2_RR1_LONG.pt\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "(0,) nan\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "LAM=1\n",
    "\n",
    "##### PAPER RESULTS\n",
    "glob_string = \"./LOGS/results_RWNURD_weight_waterbirds_BS300_seed*_RHOTEST09_BORDER7_allwd001_glr0005_FIXEDSPLIT_FINAL_LAM1_FRAC2_RR1*.pt\".format(LAM) # WATERBIRDS RESULTS, ACTUAL BORDER, reported result\n",
    "\n",
    "agg_list, consolidated_list, results_strings = parse_results(glob_string, lambda_=1)\n",
    "\n",
    "print(np.round(agg_list['test']['acc'], 2))\n",
    "print(np.round(agg_list['val']['acc'], 2))\n",
    "print(np.round(agg_list['val']['info_loss'], 2))\n",
    "print(np.round(agg_list['val']['total_loss'], 2))\n",
    "\n",
    "\n",
    "result_seeds = np.array(get_seeds_from_result_strings(results_strings))\n",
    "print(result_seeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
